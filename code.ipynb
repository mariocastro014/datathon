{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to be used in the model\n",
    "import pandas as pd\n",
    "import numpy as py\n",
    "import datetime as dt\n",
    "\n",
    "# Plotiing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Model Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "######################################3\n",
    "\n",
    "# Get unique values per column\n",
    "def print_unique_values_per_column(d):\n",
    "    for c in d.columns:\n",
    "        if (d[c].nunique() < 30):\n",
    "            print(c, d[c].nunique(), d[c].dtype, d[c].unique())\n",
    "        else:\n",
    "            print(c, d[c].nunique(), d[c].dtype)\n",
    "\n",
    "# Print missing values\n",
    "def print_missing_values(d):\n",
    "    missing_total = d.isnull().sum().sort_values(ascending=False)\n",
    "    missing_percent = (d.isnull().sum()/d.isnull().count()).sort_values(ascending=False)\n",
    "    missing = pd.concat([missing_total, missing_percent], axis=1, keys=['Total', 'Percent'])\n",
    "    missing = missing[missing['Percent'] > 0]\n",
    "    print(missing)\n",
    "\n",
    "def get_columns_with_nulls(d):\n",
    "    missing_total = d.isnull().sum().sort_values(ascending=False)\n",
    "    missing_percent = (d.isnull().sum()/d.isnull().count()).sort_values(ascending=False)\n",
    "    missing = pd.concat([missing_total, missing_percent], axis=1, keys=['Total', 'Percent'])\n",
    "    missing = missing[missing['Percent'] > 0]\n",
    "    return missing.index.values\n",
    "\n",
    "# Custom accuracy evaluation\n",
    "def accuracy_score(estimator, X, y):\n",
    "    estimator.fit(X, y)\n",
    "    y_pred = estimator.predict(X)\n",
    "    accuracy = mean(1 - mean_absolute_error(y, y_pred)/y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ofd_date</th>\n",
       "      <th>country_code</th>\n",
       "      <th>fc_codes</th>\n",
       "      <th>station_code</th>\n",
       "      <th>OFD</th>\n",
       "      <th>Slam</th>\n",
       "      <th>Earlies_Exp</th>\n",
       "      <th>Earlies_Rec</th>\n",
       "      <th>MNR_SNR_Exp</th>\n",
       "      <th>Rollover</th>\n",
       "      <th>Returns</th>\n",
       "      <th>R_Sideline</th>\n",
       "      <th>Sideline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>C</td>\n",
       "      <td>F6, F8, F14, F17</td>\n",
       "      <td>D33</td>\n",
       "      <td>14594</td>\n",
       "      <td>14568</td>\n",
       "      <td>782</td>\n",
       "      <td>896</td>\n",
       "      <td>615</td>\n",
       "      <td>767</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>C</td>\n",
       "      <td>F6, F8, F9, F14, F17, F18</td>\n",
       "      <td>D37</td>\n",
       "      <td>12736</td>\n",
       "      <td>13111</td>\n",
       "      <td>655</td>\n",
       "      <td>823</td>\n",
       "      <td>211</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>C</td>\n",
       "      <td>F1, F4, F6, F7, F13, F15, F16</td>\n",
       "      <td>D34</td>\n",
       "      <td>14562</td>\n",
       "      <td>15651</td>\n",
       "      <td>1028</td>\n",
       "      <td>1910</td>\n",
       "      <td>225</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>C</td>\n",
       "      <td>F2, F6, F7, F10, F12, F13, F14, F15, F19</td>\n",
       "      <td>D45</td>\n",
       "      <td>11165</td>\n",
       "      <td>11467</td>\n",
       "      <td>514</td>\n",
       "      <td>769</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>C</td>\n",
       "      <td>F6, F8, F13, F14, F17</td>\n",
       "      <td>D50</td>\n",
       "      <td>10006</td>\n",
       "      <td>10423</td>\n",
       "      <td>399</td>\n",
       "      <td>842</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ofd_date country_code                                  fc_codes  \\\n",
       "0  2021-06-30            C                          F6, F8, F14, F17   \n",
       "1  2021-06-30            C                 F6, F8, F9, F14, F17, F18   \n",
       "2  2021-06-30            C             F1, F4, F6, F7, F13, F15, F16   \n",
       "3  2021-06-30            C  F2, F6, F7, F10, F12, F13, F14, F15, F19   \n",
       "4  2021-06-30            C                     F6, F8, F13, F14, F17   \n",
       "\n",
       "  station_code    OFD   Slam  Earlies_Exp  Earlies_Rec  MNR_SNR_Exp  Rollover  \\\n",
       "0          D33  14594  14568          782          896          615       767   \n",
       "1          D37  12736  13111          655          823          211        29   \n",
       "2          D34  14562  15651         1028         1910          225        35   \n",
       "3          D45  11165  11467          514          769           56        39   \n",
       "4          D50  10006  10423          399          842           52        60   \n",
       "\n",
       "   Returns  R_Sideline  Sideline  \n",
       "0       35           2         4  \n",
       "1       17           2         1  \n",
       "2       47           3         1  \n",
       "3       29           0         1  \n",
       "4       65           1         1  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train_data.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the ammount of null data\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_code</th>\n",
       "      <th>OFD</th>\n",
       "      <th>Slam</th>\n",
       "      <th>Earlies_Exp</th>\n",
       "      <th>Earlies_Rec</th>\n",
       "      <th>MNR_SNR_Exp</th>\n",
       "      <th>Rollover</th>\n",
       "      <th>Returns</th>\n",
       "      <th>R_Sideline</th>\n",
       "      <th>Sideline</th>\n",
       "      <th>...</th>\n",
       "      <th>F55</th>\n",
       "      <th>F56</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>country__A</th>\n",
       "      <th>country__B</th>\n",
       "      <th>country__C</th>\n",
       "      <th>country__D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D33</td>\n",
       "      <td>14594</td>\n",
       "      <td>14568</td>\n",
       "      <td>782</td>\n",
       "      <td>896</td>\n",
       "      <td>615</td>\n",
       "      <td>767</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D37</td>\n",
       "      <td>12736</td>\n",
       "      <td>13111</td>\n",
       "      <td>655</td>\n",
       "      <td>823</td>\n",
       "      <td>211</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D34</td>\n",
       "      <td>14562</td>\n",
       "      <td>15651</td>\n",
       "      <td>1028</td>\n",
       "      <td>1910</td>\n",
       "      <td>225</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D45</td>\n",
       "      <td>11165</td>\n",
       "      <td>11467</td>\n",
       "      <td>514</td>\n",
       "      <td>769</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D50</td>\n",
       "      <td>10006</td>\n",
       "      <td>10423</td>\n",
       "      <td>399</td>\n",
       "      <td>842</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_code    OFD   Slam  Earlies_Exp  Earlies_Rec  MNR_SNR_Exp  Rollover  \\\n",
       "0          D33  14594  14568          782          896          615       767   \n",
       "1          D37  12736  13111          655          823          211        29   \n",
       "2          D34  14562  15651         1028         1910          225        35   \n",
       "3          D45  11165  11467          514          769           56        39   \n",
       "4          D50  10006  10423          399          842           52        60   \n",
       "\n",
       "   Returns  R_Sideline  Sideline  ...  F55  F56  F6  F7  F8  F9  country__A  \\\n",
       "0       35           2         4  ...    0    0   1   0   1   0           0   \n",
       "1       17           2         1  ...    0    0   1   0   1   1           0   \n",
       "2       47           3         1  ...    0    0   1   1   0   0           0   \n",
       "3       29           0         1  ...    0    0   1   1   0   0           0   \n",
       "4       65           1         1  ...    0    0   1   0   1   0           0   \n",
       "\n",
       "   country__B  country__C  country__D  \n",
       "0           0           1           0  \n",
       "1           0           1           0  \n",
       "2           0           1           0  \n",
       "3           0           1           0  \n",
       "4           0           1           0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data transformation\n",
    "\n",
    "## 1) Standarized the numerical data (if needed)\n",
    "#for column in ['']:\n",
    "#    train[column] = (train[column] - train[column].mean()) / train[column].std()\n",
    "#train\n",
    "\n",
    "## 2) Create the target column\n",
    "train[\"Target\"] = train['Earlies_Exp'] - train['MNR_SNR_Exp']\n",
    "\n",
    "## 3) Create the column of days of the week with the following coding\n",
    "\"\"\"\n",
    "0 = Monday\n",
    "1 = Tuesday\n",
    "2 = Wednesday\n",
    "3 = Thrusday\n",
    "4 = Friday\n",
    "5 = Saturday\n",
    "6 = Sunday\n",
    "\"\"\" \n",
    "train[\"ofd_date\"] = pd.to_datetime(train[\"ofd_date\"])\n",
    "train[\"dayOdWeek\"] = train['ofd_date'].dt.day_of_week\n",
    "#train[\"dayOfWeekName\"] = train['ofd_date'].dt.day_name()\n",
    "\n",
    "## 4) Create the colums per FC code.\n",
    "train = pd.concat([train, train['fc_codes'].str.get_dummies(sep=', ')], axis=1)\n",
    "\n",
    "# 5) Get the categorical data to be separated\n",
    "train = pd.get_dummies(train, prefix = ['country_'], columns = ['country_code'])\n",
    "\n",
    "# 6) Drop no relevant columns\n",
    "train = train.drop(columns=['ofd_date','fc_codes'])\n",
    "\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target         1.000000\n",
       "Earlies_Exp    0.755037\n",
       "Earlies_Rec    0.400709\n",
       "OFD            0.290058\n",
       "Sideline       0.265911\n",
       "                 ...   \n",
       "F42           -0.184277\n",
       "F43           -0.194223\n",
       "F48           -0.199170\n",
       "country__D    -0.231282\n",
       "MNR_SNR_Exp   -0.552011\n",
       "Name: Target, Length: 70, dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the correlation of the variables with the target column\n",
    "corr = train.corr()\n",
    "corr[\"Target\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the variables for the model.\n",
    "Y = train['Target']\n",
    "X = train.drop(['Target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2 fits failed out of a total of 2.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1508, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\", line 2072, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'D2'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1508, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\Mario Jesus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\", line 2072, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "ValueError: could not convert string to float: 'D33'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "#Model creation: Linear Regression \n",
    "scores = cross_val_score(LogisticRegression(), X, Y, cv=2, scoring='roc_auc')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model creation: Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model creation: SVC\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4016c711649cd93b4a24c8fe5b10f4c415c813894a9d4bfdbc019cffde92cc8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
